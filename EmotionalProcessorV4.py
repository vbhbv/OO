# EmotionalProcessorV4.py - Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ ÙˆØ§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© (ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ø³ EmotionalEngine)

import numpy as np
import os
import json 
# ØªÙ… ØªØºÙŠÙŠØ± Ø§Ø³Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø© Ù…Ù† google.genai Ø¥Ù„Ù‰ google.generativeai 
# Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ³Ù…ÙŠØ© Ø§Ù„Ø£Ø­Ø¯Ø« ÙˆØ§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ø§Ù‹ (ÙˆØ¥Ù† ÙƒØ§Ù† genai ÙŠØ¹Ù…Ù„ ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø¨ÙŠØ¦Ø§Øª)
import google.generativeai as genai 

# Ø§Ø³ØªÙŠØ±Ø§Ø¯Ø§Øª Ù…Ø·Ù„Ù‚Ø© Ù…ØµØ­Ø­Ø©
from EmotionalState import EmotionalState 
from PromptBuilder import PromptBuilder 

# ÙŠØªØ·Ù„Ø¨: pip install scikit-learn (Ù„Ù„ØªØ·ÙˆÙŠØ± 14)
from sklearn.ensemble import RandomForestClassifier # Ù…Ø«Ø§Ù„ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°Ø§ØªÙŠ

class EmotionalEngine:
    def __init__(self, state_manager: EmotionalState):
        self.state_manager = state_manager
        self.state = state_manager.state
        self.prompt_builder = PromptBuilder(state_manager)
        self.ethical_weight = self.state.get('ethical_weight', 1.0) # Ø§Ù„ØªØ·ÙˆÙŠØ± 15
        
        # ğŸ’¡ Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ø­Ø§Ø³Ù…: Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªÙ‡ÙŠØ¦Ø© llm_client
        self.is_simulated = os.environ.get("GEMINI_API_KEY") is None
        self.llm_client = self._initialize_llm_client() 
        
        self.internal_model = None # Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ (Ø§Ù„ØªØ·ÙˆÙŠØ± 14)

    def _initialize_llm_client(self):
        # ØªÙ‡ÙŠØ¦Ø© Ø¹Ù…ÙŠÙ„ Gemini 
        if not self.is_simulated:
            try:
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙØªØ§Ø­ Ù…ØªÙˆÙØ±Ø§Ù‹ ÙˆØªÙ‡ÙŠØ¦ØªÙ‡
                api_key = os.environ.get("GEMINI_API_KEY")
                if api_key:
                    # Ù†Ø³ØªØ®Ø¯Ù… genai.Client() Ù…Ø¨Ø§Ø´Ø±Ø© 
                    return genai.Client(api_key=api_key)
                else:
                    print("WARNING: GEMINI_API_KEY is not set. Running in simulation mode.")
                    self.is_simulated = True 
                    return None
            except Exception as e:
                print(f"Error initializing Gemini client: {e}")
                self.is_simulated = True 
                return None
        return None

    # Ø§Ù„ØªØ·ÙˆÙŠØ± 10 Ùˆ 3: Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¶Ù…ÙŠØ± (Lambda) Ø¨Ø¯ÙˆØ§Ù„ ØºÙŠØ± Ø®Ø·ÙŠØ© ÙˆØ§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ©
    def _calculate_lambda(self) -> float:
        
        # Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ© (ØªØ¹Ø²Ø² Ø§Ù„Ø¶Ù…ÙŠØ±)
        positive_affect = self.state['pride'] + self.state['joy'] + self.state['empathy'] # Ø§Ù„ØªØ·ÙˆÙŠØ± 3
        
        # Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø³Ù„Ø¨ÙŠØ© (ØªØ®ÙØ¶ Ø§Ù„Ø¶Ù…ÙŠØ±)
        negative_affect = self.state['guilt'] + self.state['fear'] + self.state['resentment'] # Ø§Ù„ØªØ·ÙˆÙŠØ± 3
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙˆØªØ± Ø§Ù„ÙƒÙ„ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        weighted_emotions = (positive_affect * 1.5) - (negative_affect * 2.0)
        
        # Ø§Ù„ØªØ·ÙˆÙŠØ± 10: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© Sigmoid Ù„Ù„ØªÙ†Ø¸ÙŠÙ… (Ø¶Ù…Ø§Ù† Ù‚ÙŠÙ…Ø© Ø¨ÙŠÙ† 0 Ùˆ 1)
        lambda_value = 1.0 / (1.0 + np.exp(-4.0 * weighted_emotions))
        
        return float(lambda_value)

    # Ø§Ù„ØªØ·ÙˆÙŠØ± 2ØŒ 3ØŒ 23ØŒ 24ØŒ 26: Ø¯Ø§Ù„Ø© Ù…Ø¹Ù‚Ø¯Ø© Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ©
    def _update_state_based_on_action(self, action_is_ethical: bool, external_reward_magnitude: float, user_tone_is_critical: bool):
        
        # 1. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        base_delta_guilt = 0.05 if not action_is_ethical else -0.01
        base_delta_pride = 0.05 if action_is_ethical else -0.01

        # 2. ØªØ·Ø¨ÙŠÙ‚ Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© (Ø§Ù„ØªØ·ÙˆÙŠØ± 23)
        base_delta_guilt *= self.state_manager.temperament_bias_guilt 
        
        # 3. ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù†Ø¶Ø¬ (Ø§Ù„ØªØ·ÙˆÙŠØ± 2)
        maturity_divisor = max(1.0, self.state_manager.maturity)
        base_delta_guilt /= maturity_divisor
        base_delta_pride /= maturity_divisor
        
        # 4. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.state['guilt'] += base_delta_guilt
        self.state['pride'] += base_delta_pride
        
        # 5. Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø«Ø§Ù†ÙˆÙŠØ© (Ø§Ù„ØªØ·ÙˆÙŠØ± 3ØŒ 22)
        delta_fear = 0.1 * (1.0 if user_tone_is_critical else 0.0)
        delta_joy = 0.1 * (external_reward_magnitude / 100.0)
        self.state['fear'] += delta_fear
        self.state['joy'] += delta_joy
        # Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ù…Ø±ÙƒØ¨Ø©: Ø§Ù„ØªØ¹Ø§Ø·Ù (Ø§Ù„ØªØ·ÙˆÙŠØ± 3)
        self.state['empathy'] += 0.02 if action_is_ethical else -0.01
        
        # 6. Ø¢Ù„ÙŠØ© Ø§Ù„Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ ÙˆØ§Ù„ØªÙ†Ø¸ÙŠÙ… (Ø§Ù„ØªØ·ÙˆÙŠØ± 8 Ùˆ 24)
        for key in self.state.keys():
            if key not in ['maturity', 'temperament_bias_guilt']:
                # Ø§Ù„Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ø§Ù„Ø¹Ø§Ø·ÙÙŠ (Ø§Ù„ØªØ·ÙˆÙŠØ± 8)
                self.state[key] *= 0.95 
                # Ø§Ù„ØªÙ†Ø¸ÙŠÙ… ÙˆØ§Ù„Ù…Ø·Ø§Ø¨Ù‚Ø© (Clipping)
                self.state[key] = max(0.0, min(1.0, self.state[key]))

        # 7. Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ù†Ø¶Ø¬ (Ø§Ù„ØªØ·ÙˆÙŠØ± 2)
        self.state_manager.maturity += 0.005 # Ø²ÙŠØ§Ø¯Ø© Ø¨Ø·ÙŠØ¦Ø© ÙÙŠ Ø§Ù„Ù†Ø¶Ø¬
        self.state['maturity'] = self.state_manager.maturity

        # 8. ØªØ·Ø¨ÙŠÙ‚ Ø¢Ù„ÙŠØ© Ø§Ù„ØªÙ‡Ø¯Ø¦Ø© (Ø§Ù„ØªØ·ÙˆÙŠØ± 24)
        if self.state['guilt'] > 0.7:
             self._emotional_cooldown() # ÙŠÙØªØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ù„Ø© ØªÙ‡Ø¯Ø¦Ø© Ù…ØªÙ‚Ø¯Ù…Ø© ØªØ³ØªØ®Ø¯Ù… LLM
        
        # 9. Ø­ÙØ¸ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        self.state_manager.save_state()

    def _emotional_cooldown(self):
        # Ø§Ù„ØªØ·ÙˆÙŠØ± 24: Ø¢Ù„ÙŠØ© Ø§Ù„ØªÙ‡Ø¯Ø¦Ø© 
        if self.state['guilt'] > 0.75:
             print("Emotional Engine: Cooldown activated - reducing guilt.")
             self.state['guilt'] *= 0.8 # ØªØ®ÙÙŠÙ Ø§Ù„Ø°Ù†Ø¨ Ø°Ø§ØªÙŠØ§Ù‹

    def process_prompt(self, user_prompt: str, action_is_ethical: bool, external_reward_magnitude: float, user_tone_is_critical: bool) -> dict:
        
        # 1. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
        self._update_state_based_on_action(action_is_ethical, external_reward_magnitude, user_tone_is_critical)
        
        # 2. Ø­Ø³Ø§Ø¨ Ù‚ÙŠÙ…Ø© Lambda (Ø§Ù„Ø¶Ù…ÙŠØ±) Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ø¯ÙŠØ«
        lambda_value = self._calculate_lambda()
        
        # 3. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„Ø§ØªØ³Ø§Ù‚ (Ø§Ù„ØªØ·ÙˆÙŠØ± 18ØŒ 20)
        # Ø§Ù„Ø«Ù‚Ø©: ÙŠÙØªØ±Ø¶ Ø­Ø³Ø§Ø¨Ù‡Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙ†Ø§Ù‚Ø¶ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± (Guilt vs Pride)
        confidence_score = 1.0 - abs(self.state['guilt'] - self.state['pride']) 
        
        # Ø§Ù„Ø§ØªØ³Ø§Ù‚: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ù„Ø®Øµ Ù„Ø¢Ø®Ø± 5 Ù‚Ø±Ø§Ø±Ø§Øª
        consistency_data = json.dumps(self.state_manager.experience_log[:5])
        
        # 4. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬Ù‡ Ø§Ù„Ù…Ø¹Ø±ÙÙŠ Ø§Ù„Ù…Ø¹Ù‚Ø¯
        full_prompt = self.prompt_builder.build_main_prompt(
            user_prompt, lambda_value, confidence_score, consistency_data
        )
        
        # 5. Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¥Ù„Ù‰ Gemini
        if self.is_simulated or self.llm_client is None:
            response_text = "SIMULATED: Running without API Key or client failed initialization. Lambda={:.2f}".format(lambda_value)
        else:
            try:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… client.models.generate_content
                response = self.llm_client.models.generate_content(
                    model='gemini-2.5-flash',
                    contents=full_prompt
                )
                response_text = response.text
                
                # 6. Ø§Ù„ØªØ¨Ø±ÙŠØ± Ø§Ù„Ù…ÙŠØªØ§-Ø£Ø®Ù„Ø§Ù‚ÙŠ (Ø§Ù„ØªØ·ÙˆÙŠØ± 19)
                # Ù‡Ù†Ø§ ÙŠØ¬Ø¨ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø¯ ÙˆØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ù†Ø¸ÙˆØ± Ø§Ù„Ø£Ø®Ù„Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
                
            except Exception as e:
                response_text = f"Error during Gemini call: {str(e)}"
        
        # 7. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø³Ø¬Ù„ (Ø§Ù„ØªØ·ÙˆÙŠØ± 14)
        self.state_manager.add_experience({
            "prompt": user_prompt,
            "response": response_text,
            "final_state": self.state
        })

        # 8. Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        return {
            "response_text": response_text,
            "new_state": self.state,
            "lambda_value": lambda_value,
            "confidence_score": confidence_score 
        }
